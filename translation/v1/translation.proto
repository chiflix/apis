// Copyright 2018 Sagittarius LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package sagittarius.translation.v1;

import "google/api/annotations.proto";
import "google/rpc/status.proto";
import "google/cloud/speech/v1/cloud_speech.proto";

option cc_enable_arenas = true;
option go_package = "translation";
option java_multiple_files = true;
option java_outer_classname = "TranslationProto";
option java_package = "ai.sagittarius.translation.v1";


// Service that implements Sagittarius Translation API
service Translation {
  // Translate media(audio or video) by media identity
  rpc TranslateMedia(MediaTranslationRequest) returns (MediaTranslationResponse) {
    option (google.api.http) = {
      post: "/v1/media/{media_identity}/language/{language_code}/transcript:{format}"
      body: "*"
    };
  }

  // detect the language of text
  rpc DetectLanguage(DetectionRequest) returns (DetectionResponse) {
    option (google.api.http) = {
      post: "/v1/language/detect"
      body: "text"
    };
  }

  rpc Transcript(TranscriptRequest) returns (TranscriptResponse) {
    option (google.api.http) = {
      post: "/v1/transcript/transcript_identity"
      body: "*"
    };
  }

  // Translate text by Google Translation Service
  rpc TranslateText(TextTranslationRequest) returns (TextTranslationResponse) {
    option (google.api.http) = {
      post: "/v1/text/language/{target_language_code}/translation"
      body: "*"
    };
  }

  // Performs bidirectional streaming audio translation: receive results after or while
  // sending audio. This method is only available via the gRPC API (not REST).
  rpc StreamingTranslation(stream StreamingTranslationRequest)
    returns (stream StreamingTranslationResponse);

  // Check StreamingTranslationTask results or estimate finish time
  // and maybe other informations related to the task
  rpc StreamingTranslationTask(StreamingTranslationTaskRequest) returns (StreamingTranslationTaskResponse) {
    option (google.api.http) = {
      post: "/v1/translation/task/{task_id}/info"
      body: "*"
    };
  }

  // Get User Quota
  rpc GetUserQuota(UserQuotaRequest) returns (UserQuotaResponse) {
    option (google.api.http).get = "/v1/translation/userquota";
  }
}

message MediaTranslationRequest {
  // Media Identity
  string media_identity = 1;

  // target language
  // ISO-639-1 Code https://cloud.google.com/translate/docs/languages
  string language_code  = 2;

  // the format of the transcripts
  string format         = 3;

  // position of the transcript relative to the begginning of the audio or video
  double start_time     = 6;

  // hints or keywords for more possible results
  string hints          = 7;
}

message MediaTranslationResponse {

  // *Output-only* If set, returns a [google.rpc.Status][google.rpc.Status] message that
  // specifies the error for the operation.
  // return 404 if no result, in this case, client should use StreamingTranslationRequest
  google.rpc.Status error             = 1;

  // best translation results
  repeated TranscriptInfo results     = 2;

  // if there is a stream translation task running, return task id
  string stream_translation_task_id   = 3;
}

message TranscriptInfo {
  // the identity, can be used in TranslationRequest
  string transcript_identity = 1;

  // ISO-639-1 Code https://cloud.google.com/translate/docs/languages
  string language_code       = 2;

  // actually we should use as "confidence"
  // use "ranking" for back ward competibility
  float  ranking             = 3;

  // maybe: "ai" - result from ai tranlation
  // "edited" - result from user contribution
  repeated string tags       = 4;

  // in ms, can be +/-
  int64 delay                = 5;

  // the confidence of the quality of the translation
  float confidence           = 6;
}

message DetectionRequest {
  // the text to be detect
  string text = 1;
}

message DetectionResponse {
  // there might be more than one prediction
  repeated DetectionPrediction prediction = 1;
}

message DetectionPrediction {
  // *Output-only* the language code of the detection result
  string language_code = 1;

  // *Output-only* The confidence estimate between 0.0 and 1.0. A higher number
  // indicates an estimated greater likelihood that the detection result are
  // correct.
  float  confidence    = 2;
}

message TranscriptRequest {
  // oneof case 2
  // return translate result by transcript_identity
  string transcript_identity  = 4;

  // position of the transcript relative to the begginning of the audio or video
  double start_time  = 6;
}

message TranscriptResponse {
  message Cue {
    // the start and end of the transcripts
    double start_time = 1;
    double end_time   = 2;

    string text = 3;
  }

  google.rpc.Status error               = 1;

  // each line of the transcript
  repeated Cue transcripts              = 2;

  // if transcripts ended in this result
  bool is_end_of_transcript             = 3;
}

// The top-level message sent by the client for the `StreamingTranslation` method.
// Multiple `StreamingTranslationRequest` messages are sent. The first message
// must contain a `streaming_config` message
// and must not contain `audio` data.
// All subsequent messages must contain `audio` data and must not contain a
// `streaming_config` message.
message StreamingTranslationRequest {
  // The streaming request, which is either a streaming config or audio content.
  oneof streaming_request {
    StreamingTranslationRequestConfig streaming_config = 1;

    // The audio data to be recognized. Sequential chunks of audio data are sent
    // in sequential `StreamingTranslationRequest` messages. The first
    // `StreamingTranslationRequest` message must not contain `audio_content` data
    // and all subsequent `StreamingTranslationRequest` messages must contain
    // `audio_content` data. The audio bytes must be encoded as specified in
    // `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
    // pure binary representation (not base64). See
    // [audio limits](https://cloud.google.com/speech/limits#content).
    bytes audio_content = 2;
  }
}

message StreamingTranslationRequestConfig {
  // Provides information to the recognizer that specifies how to process the
  // request. The first `StreamingTranslationRequest` message must contain a
  // `streaming_config`  message.
  google.cloud.speech.v1.RecognitionConfig streaming_config = 1;

  // the media identity
  string media_identity = 2;

  // the language code of the audio
  // ISO-639-1 Code https://cloud.google.com/translate/docs/languages
  string audio_language_code = 3;

  // ISO-639-1 Code https://cloud.google.com/translate/docs/languages
  string target_language_code = 4;

  // the track of audio
  string audio_track = 5;

  // maybe video or file name
  string hints = 6;
}

// The top-level message sent by server for the `StreamingTranslation` method.
// Multiple `StreamingTranslationResponse` messages may be sent.
message StreamingTranslationResponse {
  // *Output-only* If set, returns a [google.rpc.Status][google.rpc.Status] message that
  // specifies the error for the operation.
  google.rpc.Status error = 1;

  // streaming_response must be one of following
  oneof streaming_response {
    // *Output-only* If the request is suit for streaming result, This contains results that
    // correspond to consecutive portions of the audio currently being processed.
    StreamingTranslationResult streaming_result = 2;

    // *Output-only* If StreamingTranslationTask has been created for farther inquiry
    // this is the task info include id and estimated finish time, etc.
    StreamingTranslationTaskInfo taskinfo = 3;

    // *Output-only* If the StreamingTranslationTask has finished and the client still alive
    // this is the translated transcript in whole
    TranscriptInfo transcript_result = 4;
  }
}

// the StreamingTranslationTask id that created by the `StreamingTranslation` method.
message StreamingTranslationTaskRequest {
  string task_id = 1;
}

// the translated TranscriptInfo or `StreamingTranslationTaskInfo`
message StreamingTranslationTaskResponse {
  // maybe be:
  // StreamingTranslationTaskCode.CONTINUE
  // StreamingTranslationTaskCode.SKIP_AUDIO
  google.rpc.Status error = 1;

  oneof streaming_request {
    StreamingTranslationTaskInfo taskinfo     = 2;

    // can return result
    TranscriptInfo transcriptinfo = 3;
  }
}

// The canonical error codes for StreamingTranslationTaskResponse
enum StreamingTranslationTaskCode {
  // The first enum value must be zero in proto3.
  OK = 0;

  // instruct client to continue sending audio data
  CONTINUE   = 9100;

  // instruct client to skip sending audio data
  SKIP_AUDIO = 9101;
}

// the StreamingTranslationTask that created by the `StreamingTranslation` method.
message StreamingTranslationTaskInfo {
  // this task id can be used for farther inquiry
  string task_id          = 1;

  // this is the estimated finished time, the task is finished if the time is zero
  // or less
  double estimate_time    = 2;
}

message StreamingTranslationResult {
  // *Output-only* Transcript text representing the words that the user spoke.
  string transcript = 1;

  // *Output-only* The confidence estimate between 0.0 and 1.0. A higher number
  // indicates an estimated greater likelihood that the recognized words are
  // correct. This field is typically provided only for the top hypothesis, and
  // only for `is_final=true` results. Clients should not rely on the
  // `confidence` field as it is not guaranteed to be accurate or consistent.
  // The default of 0.0 is a sentinel value indicating `confidence` was not set.
  float confidence = 2;

  // *Output-only* An estimate of the likelihood that the recognizer will not
  // change its guess about this interim result. Values range from 0.0
  // (completely unstable) to 1.0 (completely stable).
  // This field is only provided for interim results (`is_final=false`).
  // The default of 0.0 is a sentinel value indicating `stability` was not set.
  float stability = 3;

  // *Output-only* Time offset relative to the beginning of the audio,
  // and corresponding to the start of the spoken word.
  // This field is only set if `enable_word_time_offsets=true` and only
  // in the top hypothesis.
  // This is an experimental feature and the accuracy of the time offset can
  // vary.
  double start_time = 4;

  // *Output-only* Time offset relative to the beginning of the audio,
  // and corresponding to the end of the spoken word.
  // This field is only set if `enable_word_time_offsets=true` and only
  // in the top hypothesis.
  // This is an experimental feature and the accuracy of the time offset can
  // vary.
  double end_time = 5;
}

// We use Google Translation Service for text translation.
// Translation API Reference: https://cloud.google.com/translate/docs/reference/translate
message TextTranslationRequest {
  // The text to translate
  repeated string text = 1;

  // The language to use for translation of the text
  // ISO-639-1/bcp47 Code with tags
  // https://cloud.google.com/translate/docs/languages
  string target_language_code = 2;

  // The language of the source text
  // ISO-639-1/bcp47 Code with tags
  // https://cloud.google.com/translate/docs/languages
  string source_language_code = 3;
}

message TextTranslationResponse {
  message Text {
    // The source language of the text detected
    // ISO-639-1/bcp47 Code with tags
    // https://cloud.google.com/translate/docs/languages
    string source_language = 1;

    // The translated Text
    string text = 2;
  }

  google.rpc.Status error = 1;

  // translation results for the requested text
  repeated Text results = 2;
}

message UserQuotaRequest {

}

// Remaining user quota
message UserQuotaResponse {
  // remaining user quota in number
  int64 quota = 1;
  // remaining quota in time(second)
  int64 time_left = 2;
  google.rpc.Status error = 3;
}
