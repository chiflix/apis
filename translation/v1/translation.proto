// Copyright 2018 Sagittarius LLC.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

syntax = "proto3";

package sagittarius.translation.v1;

import "google/api/annotations.proto";
import "google/protobuf/duration.proto";
import "google/rpc/status.proto";
import "google/cloud/speech/v1/cloud_speech.proto";

option cc_enable_arenas = true;
option go_package = "translation";
option java_multiple_files = true;
option java_outer_classname = "TranslationProto";
option java_package = "ai.sagittarius.translation.v1";


// Service that implements Sagittarius Translation API
service Translation {
  // Translate media(audio or video) by media identity
  rpc TranslateMedia(MediaTranslationRequest) returns (MediaTranslationResponse) {
    option (google.api.http) = {
      get: "/v1/media/{media_identity}/language/{language_code}/transcript:{format}"
      body: "*"
    };
  }

  // detect the language of text
  rpc DetectLanguage(DetectionRequest) returns (DetectionResponse) {
    option (google.api.http) = {
      get: "/v1/language/detect"
      body: "text"
    };
  }

  rpc Transcript(TranscriptRequest) returns (MediaTranslationResponse) {
    option (google.api.http) = {
      get: "/v1/transcript/transcript_identity"
      body: "*"
    };
  }

  // Performs bidirectional streaming audio translation: receive results while
  // sending audio. This method is only available via the gRPC API (not REST).
  rpc StreamingTranslation(stream StreamingTranslationRequest)
    returns (stream StreamingTranslationResponse);
}

message MediaTranslationRequest {
  // Media Identity
  string media_identity = 1;

  // oneof case 1
  // target language
  // ISO-639-1 Code https://cloud.google.com/translate/docs/languages
  string language_code  = 2;

  // the format of the transcripts
  string format         = 3;

  // position of the transcript relative to the begginning of the audio or video
  google.protobuf.Duration start_time  = 6;

  // names for more possible results
  string extra_names    = 7;
}

message MediaTranslationResponse {
  message Cue {
    // the start and end of the transcripts
    google.protobuf.Duration start_time = 1;
    google.protobuf.Duration end_time   = 2;

    string text = 3;
  }

  // *Output-only* If set, returns a [google.rpc.Status][google.rpc.Status] message that
  // specifies the error for the operation.
  // return 404 if no result, in this case, client should use StreamingTranslationRequest
  google.rpc.Status error             = 1;

  // the identity, can be used in TranslationRequest
  string transcript_identity          = 2;

  // total line of the transcripts there should be
  bool to_be_continued                = 3;

  // each line of the transcript
  repeated Cue transcripts            = 4;

  // next best translation results
  repeated string nextbest_transcript_id = 5;
}

message DetectionRequest {
  // the text to be detect
  string text = 1;
}

message DetectionResponse {
  // *Output-only* the language code of the detection result
  string language_code = 1;

  // *Output-only* The confidence estimate between 0.0 and 1.0. A higher number
  // indicates an estimated greater likelihood that the detection result are
  // correct.
  float  confidence    = 2;
}

message TranscriptRequest {
  // oneof case 2
  // return translate result by transcript_identity
  string transcript_identity  = 4;

  // position of the transcript relative to the begginning of the audio or video
  google.protobuf.Duration start_time  = 6;
}

// The top-level message sent by the client for the `StreamingRecognize` method.
// Multiple `StreamingTranslationRequest` messages are sent. The first message
// must contain a `streaming_config` message and must not contain `audio` data.
// All subsequent messages must contain `audio` data and must not contain a
// `streaming_config` message.
message StreamingTranslationRequest {
  // The streaming request, which is either a streaming config or audio content.
  oneof streaming_request {
    // Provides information to the recognizer that specifies how to process the
    // request. The first `StreamingTranslationRequest` message must contain a
    // `streaming_config`  message.
    google.cloud.speech.v1.RecognitionConfig streaming_config = 1;

    // The audio data to be recognized. Sequential chunks of audio data are sent
    // in sequential `StreamingTranslationRequest` messages. The first
    // `StreamingTranslationRequest` message must not contain `audio_content` data
    // and all subsequent `StreamingTranslationRequest` messages must contain
    // `audio_content` data. The audio bytes must be encoded as specified in
    // `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
    // pure binary representation (not base64). See
    // [audio limits](https://cloud.google.com/speech/limits#content).
    bytes audio_content = 2;
  }
}

message StreamingTranslationResponse {
  // *Output-only* If set, returns a [google.rpc.Status][google.rpc.Status] message that
  // specifies the error for the operation.
  google.rpc.Status error = 1;

  // *Output-only* This repeated list contains zero or more results that
  // correspond to consecutive portions of the audio currently being processed.
  // It contains zero or more `is_final=false` results followed by zero or one
  // `is_final=true` result (the newly settled portion).
  repeated StreamingTranslationResult results = 2;
}

message StreamingTranslationResult {
  // *Output-only* Transcript text representing the words that the user spoke.
  string transcript = 1;

  // *Output-only* The confidence estimate between 0.0 and 1.0. A higher number
  // indicates an estimated greater likelihood that the recognized words are
  // correct. This field is typically provided only for the top hypothesis, and
  // only for `is_final=true` results. Clients should not rely on the
  // `confidence` field as it is not guaranteed to be accurate or consistent.
  // The default of 0.0 is a sentinel value indicating `confidence` was not set.
  float confidence = 2;

  // *Output-only* An estimate of the likelihood that the recognizer will not
  // change its guess about this interim result. Values range from 0.0
  // (completely unstable) to 1.0 (completely stable).
  // This field is only provided for interim results (`is_final=false`).
  // The default of 0.0 is a sentinel value indicating `stability` was not set.
  float stability = 3;

  // *Output-only* Time offset relative to the beginning of the audio,
  // and corresponding to the start of the spoken word.
  // This field is only set if `enable_word_time_offsets=true` and only
  // in the top hypothesis.
  // This is an experimental feature and the accuracy of the time offset can
  // vary.
  google.protobuf.Duration start_time = 4;

  // *Output-only* Time offset relative to the beginning of the audio,
  // and corresponding to the end of the spoken word.
  // This field is only set if `enable_word_time_offsets=true` and only
  // in the top hypothesis.
  // This is an experimental feature and the accuracy of the time offset can
  // vary.
  google.protobuf.Duration end_time = 5;
}
